{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad6a84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de exemplos carregados: 336\n",
      "Treino: 268 | Teste: 68\n",
      "Tokens de treino: 2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75/75 [00:08<00:00,  8.74it/s]\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š RelatÃ³rio de desempenho:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   CATEGORIA       1.00      1.00      1.00        68\n",
      "         COR       1.00      0.83      0.91        36\n",
      "       MARCA       0.97      1.00      0.98        62\n",
      "     MEMORIA       1.00      1.00      1.00        65\n",
      "      MODELO       0.98      1.00      0.99       109\n",
      "           O       0.98      0.98      0.98       245\n",
      "\n",
      "    accuracy                           0.98       585\n",
      "   macro avg       0.99      0.97      0.98       585\n",
      "weighted avg       0.98      0.98      0.98       585\n",
      "\n",
      " Modelo salvo em: ../models/sbert_iphone_model\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ----------------------------\n",
    "# 1ï¸ Carregar dataset JSONL\n",
    "# ----------------------------\n",
    "DATA_PATH = Path(\"../data/annotations/iphone_auto_annotations.jsonl\")\n",
    "\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "data = load_jsonl(DATA_PATH)\n",
    "print(f\"Total de exemplos carregados: {len(data)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2ï¸ DivisÃ£o treino/teste\n",
    "# ----------------------------\n",
    "random.shuffle(data)\n",
    "split = int(len(data) * 0.8)\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]\n",
    "\n",
    "print(f\"Treino: {len(train_data)} | Teste: {len(test_data)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3ï¸ Preparar dados para SBERT\n",
    "# ----------------------------\n",
    "def flatten_dataset(dataset):\n",
    "    texts, labels = [], []\n",
    "    for item in dataset:\n",
    "        text = item[\"text\"]\n",
    "        ents = item[\"entities\"]\n",
    "\n",
    "        # Divide o texto em tokens e calcula offsets de inÃ­cio/fim\n",
    "        tokens = text.split()\n",
    "        offsets = []\n",
    "        pos = 0\n",
    "        for tok in tokens:\n",
    "            start = text.find(tok, pos)\n",
    "            end = start + len(tok)\n",
    "            offsets.append((start, end))\n",
    "            pos = end\n",
    "\n",
    "        # Inicializa rÃ³tulos como \"O\" (fora de entidade)\n",
    "        token_labels = [\"O\"] * len(tokens)\n",
    "        for start, end, label in ents:\n",
    "            for i, (tok_start, tok_end) in enumerate(offsets):\n",
    "                # Marca tokens que estÃ£o dentro do span da entidade\n",
    "                if tok_start >= start and tok_end <= end:\n",
    "                    token_labels[i] = label\n",
    "\n",
    "        texts.extend(tokens)\n",
    "        labels.extend(token_labels)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "X_train_tokens, y_train = flatten_dataset(train_data)\n",
    "X_test_tokens, y_test = flatten_dataset(test_data)\n",
    "\n",
    "print(f\"Tokens de treino: {len(X_train_tokens)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4ï¸ Gerar embeddings com SBERT\n",
    "# ----------------------------\n",
    "sbert_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(sbert_model_name)\n",
    "\n",
    "X_train_emb = model.encode(X_train_tokens, convert_to_numpy=True, show_progress_bar=True)\n",
    "X_test_emb = model.encode(X_test_tokens, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 5ï¸ Treinar classificador\n",
    "# ----------------------------\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_emb, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# 6ï¸ Avaliar modelo\n",
    "# ----------------------------\n",
    "y_pred = clf.predict(X_test_emb)\n",
    "print(\"\\nðŸ“Š RelatÃ³rio de desempenho:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ----------------------------\n",
    "# 7ï¸ Salvar modelo treinado\n",
    "# ----------------------------\n",
    "MODEL_DIR = Path(\"../models/sbert_iphone_model\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Salva o classificador\n",
    "joblib.dump(clf, MODEL_DIR / \"logreg_model.pkl\")\n",
    "\n",
    "# Salva o nome do modelo SBERT\n",
    "with open(MODEL_DIR / \"sbert_model_name.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sbert_model_name)\n",
    "\n",
    "print(f\" Modelo salvo em: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796b4f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teste de prediÃ§Ã£o usando o modelo salvo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victor.miguel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iphone â†’ CATEGORIA\n",
      "14 â†’ MODELO\n",
      "Pro â†’ MODELO\n",
      "128GB â†’ MEMORIA\n",
      "Azul â†’ COR\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "MODEL_DIR = Path(\"../models/sbert_iphone_model\")\n",
    "\n",
    "# ----------------------------\n",
    "# 8ï¸ Teste de prediÃ§Ã£o (modelo carregado)\n",
    "# ----------------------------\n",
    "print(\"\\nTeste de prediÃ§Ã£o usando o modelo salvo:\")\n",
    "\n",
    "# Recarrega o modelo salvo\n",
    "clf_loaded = joblib.load(MODEL_DIR / \"logreg_model.pkl\")\n",
    "with open(MODEL_DIR / \"sbert_model_name.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sbert_name = f.read().strip()\n",
    "model_loaded = SentenceTransformer(sbert_name)\n",
    "\n",
    "# Frase de exemplo\n",
    "sample_text = \"iphone 14 Pro 128GB Azul\"\n",
    "tokens = sample_text.split()\n",
    "embs = model_loaded.encode(tokens)\n",
    "preds = clf_loaded.predict(embs)\n",
    "\n",
    "for tok, label in zip(tokens, preds):\n",
    "    print(f\"{tok} â†’ {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
