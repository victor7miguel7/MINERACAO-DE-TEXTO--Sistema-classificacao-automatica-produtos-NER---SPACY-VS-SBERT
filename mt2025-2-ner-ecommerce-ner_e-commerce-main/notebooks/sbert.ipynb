{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad6a84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de exemplos carregados: 336\n",
      "Treino: 268 | Teste: 68\n",
      "Tokens de treino: 2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 75/75 [00:08<00:00,  8.74it/s]\n",
      "Batches: 100%|██████████| 19/19 [00:01<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Relatório de desempenho:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   CATEGORIA       1.00      1.00      1.00        68\n",
      "         COR       1.00      0.83      0.91        36\n",
      "       MARCA       0.97      1.00      0.98        62\n",
      "     MEMORIA       1.00      1.00      1.00        65\n",
      "      MODELO       0.98      1.00      0.99       109\n",
      "           O       0.98      0.98      0.98       245\n",
      "\n",
      "    accuracy                           0.98       585\n",
      "   macro avg       0.99      0.97      0.98       585\n",
      "weighted avg       0.98      0.98      0.98       585\n",
      "\n",
      " Modelo salvo em: ../models/sbert_iphone_model\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# ----------------------------\n",
    "# 1️ Carregar dataset JSONL\n",
    "# ----------------------------\n",
    "DATA_PATH = Path(\"../data/annotations/iphone_auto_annotations.jsonl\")\n",
    "\n",
    "def load_jsonl(path):\n",
    "    data = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "data = load_jsonl(DATA_PATH)\n",
    "print(f\"Total de exemplos carregados: {len(data)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2️ Divisão treino/teste\n",
    "# ----------------------------\n",
    "random.shuffle(data)\n",
    "split = int(len(data) * 0.8)\n",
    "train_data = data[:split]\n",
    "test_data = data[split:]\n",
    "\n",
    "print(f\"Treino: {len(train_data)} | Teste: {len(test_data)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 3️ Preparar dados para SBERT\n",
    "# ----------------------------\n",
    "def flatten_dataset(dataset):\n",
    "    texts, labels = [], []\n",
    "    for item in dataset:\n",
    "        text = item[\"text\"]\n",
    "        ents = item[\"entities\"]\n",
    "\n",
    "        # Divide o texto em tokens e calcula offsets de início/fim\n",
    "        tokens = text.split()\n",
    "        offsets = []\n",
    "        pos = 0\n",
    "        for tok in tokens:\n",
    "            start = text.find(tok, pos)\n",
    "            end = start + len(tok)\n",
    "            offsets.append((start, end))\n",
    "            pos = end\n",
    "\n",
    "        # Inicializa rótulos como \"O\" (fora de entidade)\n",
    "        token_labels = [\"O\"] * len(tokens)\n",
    "        for start, end, label in ents:\n",
    "            for i, (tok_start, tok_end) in enumerate(offsets):\n",
    "                # Marca tokens que estão dentro do span da entidade\n",
    "                if tok_start >= start and tok_end <= end:\n",
    "                    token_labels[i] = label\n",
    "\n",
    "        texts.extend(tokens)\n",
    "        labels.extend(token_labels)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "X_train_tokens, y_train = flatten_dataset(train_data)\n",
    "X_test_tokens, y_test = flatten_dataset(test_data)\n",
    "\n",
    "print(f\"Tokens de treino: {len(X_train_tokens)}\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4️ Gerar embeddings com SBERT\n",
    "# ----------------------------\n",
    "sbert_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(sbert_model_name)\n",
    "\n",
    "X_train_emb = model.encode(X_train_tokens, convert_to_numpy=True, show_progress_bar=True)\n",
    "X_test_emb = model.encode(X_test_tokens, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 5️ Treinar classificador\n",
    "# ----------------------------\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_emb, y_train)\n",
    "\n",
    "# ----------------------------\n",
    "# 6️ Avaliar modelo\n",
    "# ----------------------------\n",
    "y_pred = clf.predict(X_test_emb)\n",
    "print(\"\\n📊 Relatório de desempenho:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ----------------------------\n",
    "# 7️ Salvar modelo treinado\n",
    "# ----------------------------\n",
    "MODEL_DIR = Path(\"../models/sbert_iphone_model\")\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Salva o classificador\n",
    "joblib.dump(clf, MODEL_DIR / \"logreg_model.pkl\")\n",
    "\n",
    "# Salva o nome do modelo SBERT\n",
    "with open(MODEL_DIR / \"sbert_model_name.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(sbert_model_name)\n",
    "\n",
    "print(f\" Modelo salvo em: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796b4f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teste de predição usando o modelo salvo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victor.miguel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.7.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iphone → CATEGORIA\n",
      "14 → MODELO\n",
      "Pro → MODELO\n",
      "128GB → MEMORIA\n",
      "Azul → COR\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "MODEL_DIR = Path(\"../models/sbert_iphone_model\")\n",
    "\n",
    "# ----------------------------\n",
    "# 8️ Teste de predição (modelo carregado)\n",
    "# ----------------------------\n",
    "print(\"\\nTeste de predição usando o modelo salvo:\")\n",
    "\n",
    "# Recarrega o modelo salvo\n",
    "clf_loaded = joblib.load(MODEL_DIR / \"logreg_model.pkl\")\n",
    "with open(MODEL_DIR / \"sbert_model_name.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    sbert_name = f.read().strip()\n",
    "model_loaded = SentenceTransformer(sbert_name)\n",
    "\n",
    "# Frase de exemplo\n",
    "sample_text = \"iphone 14 Pro 128GB Azul\"\n",
    "tokens = sample_text.split()\n",
    "embs = model_loaded.encode(tokens)\n",
    "preds = clf_loaded.predict(embs)\n",
    "\n",
    "for tok, label in zip(tokens, preds):\n",
    "    print(f\"{tok} → {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
